{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    brier_score_loss\n",
    ")\n",
    "import joblib\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils import resample\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596393a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X_test':         num__annual_inc  num__avg_cur_bal  num__bc_open_to_buy  num__bc_util  \\\n",
      "951469        -0.908541         -0.684762            -0.655219      1.311575   \n",
      "951470        -0.414255          0.993807             0.145469      0.201937   \n",
      "951471        -0.505971         -0.486715             0.213401     -0.598282   \n",
      "951472         0.054126          0.329806            -0.415431     -0.971717   \n",
      "951473        -0.278432         -0.576017            -0.602115      1.293792   \n",
      "...                 ...               ...                  ...           ...   \n",
      "985662        -0.418456         -0.612487             0.013196     -2.156042   \n",
      "985663         3.554732         -0.673893             4.323966     -1.871519   \n",
      "985664        -0.803522          0.253365            -0.519485      0.312190   \n",
      "985665        -0.348444          1.316056            -0.565078     -1.611893   \n",
      "985666         0.596720          0.368027            -0.032593     -1.227787   \n",
      "\n",
      "        num__delinq_2yrs  num__dti  num__emp_length  num__fico_range_high  \\\n",
      "951469         -0.370384 -0.769822        -0.806094             -0.946979   \n",
      "951470          0.729341  2.382828        -0.266259             -1.116596   \n",
      "951471         -0.370384  0.292497        -0.806094             -0.438127   \n",
      "951472          0.729341  0.382403         1.083330             -0.268510   \n",
      "951473         -0.370384 -0.439770        -0.806094             -0.098893   \n",
      "...                  ...       ...              ...                   ...   \n",
      "985662          0.729341 -0.148756        -1.076012              0.070724   \n",
      "985663          0.729341 -1.177952        -1.076012              0.749193   \n",
      "985664         -0.370384 -0.333302         1.083330              0.409959   \n",
      "985665         -0.370384 -1.279688         0.813412             -1.116596   \n",
      "985666         -0.370384 -0.359327         1.083330              0.918810   \n",
      "\n",
      "        num__funded_amnt  num__inq_last_6mths  ...  num__pub_rec  \\\n",
      "951469         -1.368343            -0.694720  ...     -0.384455   \n",
      "951470         -0.097956            -0.694720  ...     -0.384455   \n",
      "951471         -1.477081             0.372623  ...     -0.384455   \n",
      "951472         -0.999692             0.372623  ...     -0.384455   \n",
      "951473          0.474911            -0.694720  ...     -0.384455   \n",
      "...                  ...                  ...  ...           ...   \n",
      "985662         -1.368343            -0.694720  ...     -0.384455   \n",
      "985663         -0.628389            -0.694720  ...     -0.384455   \n",
      "985664         -1.052735             0.372623  ...     -0.384455   \n",
      "985665         -1.370995            -0.694720  ...     -0.384455   \n",
      "985666         -0.840562             0.372623  ...     -0.384455   \n",
      "\n",
      "        num__pub_rec_bankruptcies  num__revol_bal  num__revol_util  \\\n",
      "951469                  -0.359252       -0.646825        -0.374358   \n",
      "951470                  -0.359252        2.182867         0.556027   \n",
      "951471                  -0.359252       -0.099237        -0.739135   \n",
      "951472                  -0.359252       -0.691598        -0.796515   \n",
      "951473                  -0.359252        0.700664         1.527399   \n",
      "...                           ...             ...              ...   \n",
      "985662                  -0.359252       -0.773731        -2.161354   \n",
      "985663                  -0.359252        0.096173        -1.472787   \n",
      "985664                  -0.359252       -0.559575        -0.173526   \n",
      "985665                  -0.359252       -0.762572        -1.534266   \n",
      "985666                  -0.359252       -0.496497        -0.706346   \n",
      "\n",
      "        num__tax_liens  label__emp_title  label__home_ownership  \\\n",
      "951469       -0.156755              33.0                    2.0   \n",
      "951470       -0.156755               3.0                    0.0   \n",
      "951471       -0.156755              47.0                    2.0   \n",
      "951472       -0.156755              33.0                    1.0   \n",
      "951473       -0.156755              33.0                    2.0   \n",
      "...                ...               ...                    ...   \n",
      "985662       -0.156755              33.0                    2.0   \n",
      "985663       -0.156755              33.0                    1.0   \n",
      "985664       -0.156755              33.0                    0.0   \n",
      "985665       -0.156755              33.0                    0.0   \n",
      "985666       -0.156755              33.0                    0.0   \n",
      "\n",
      "        label__purpose  ord__grade  ord__sub_grade  \n",
      "951469             2.0         2.0            14.0  \n",
      "951470             2.0         3.0            15.0  \n",
      "951471             0.0         2.0            13.0  \n",
      "951472             2.0         0.0             4.0  \n",
      "951473             2.0         3.0            16.0  \n",
      "...                ...         ...             ...  \n",
      "985662             8.0         0.0             4.0  \n",
      "985663             2.0         2.0            10.0  \n",
      "985664             1.0         1.0             7.0  \n",
      "985665             3.0         2.0            11.0  \n",
      "985666             3.0         0.0             3.0  \n",
      "\n",
      "[34198 rows x 31 columns], 'y_test': 951469    0\n",
      "951470    0\n",
      "951471    0\n",
      "951472    0\n",
      "951473    0\n",
      "         ..\n",
      "985662    0\n",
      "985663    0\n",
      "985664    0\n",
      "985665    0\n",
      "985666    0\n",
      "Name: target, Length: 34198, dtype: int32, 'y_pred_test': array([0, 1, 0, ..., 0, 0, 0]), 'y_proba': array([0.45213735, 0.56139556, 0.48333844, ..., 0.22068394, 0.11917988,\n",
      "       0.15896814]), 'X_train':          num__annual_inc  num__avg_cur_bal  num__bc_open_to_buy  num__bc_util  \\\n",
      "0              -0.740512         -0.745082             0.749479     -1.586997   \n",
      "1              -0.470965         -0.250508             0.416937     -0.242629   \n",
      "2               4.254853          2.390279             0.248935      0.226833   \n",
      "3               0.841762          1.367198            -0.426078      1.147974   \n",
      "4              -0.155910          0.630499            -0.342077      0.497129   \n",
      "...                  ...               ...                  ...           ...   \n",
      "1086231         0.316671          0.886934             0.584482     -1.654571   \n",
      "1086232         0.439193         -0.494564             0.703429     -1.234901   \n",
      "1086233        -0.295935         -0.603490             1.054195     -1.284692   \n",
      "1086234        -0.716007         -0.630601            -0.159313     -1.963989   \n",
      "1086235         0.416439          0.376540            -0.456125      0.706965   \n",
      "\n",
      "         num__delinq_2yrs  num__dti  num__emp_length  num__fico_range_high  \\\n",
      "0               -0.370384 -1.880644        -1.076012              2.106130   \n",
      "1               -0.370384  0.530276         1.083330              1.258044   \n",
      "2               -0.370384  0.019227        -0.266259              1.766896   \n",
      "3               -0.370384 -0.633779         1.083330              0.749193   \n",
      "4                0.729341  0.561034         0.003659             -0.946979   \n",
      "...                   ...       ...              ...                   ...   \n",
      "1086231         -0.370384 -1.190965        -1.615847             -0.268510   \n",
      "1086232          2.928791 -0.797031        -1.615847             -0.777361   \n",
      "1086233          0.729341  0.137526         1.083330              1.088427   \n",
      "1086234          0.729341  0.189577        -0.266259             -0.777361   \n",
      "1086235          0.729341  1.049606        -0.536176              0.070724   \n",
      "\n",
      "         num__funded_amnt  num__inq_last_6mths  ...  num__pub_rec  \\\n",
      "0               -1.180039             1.439967  ...     -0.384455   \n",
      "1                1.180387            -0.694720  ...     -0.384455   \n",
      "2                1.281169             0.372623  ...     -0.384455   \n",
      "3               -0.416216             0.372623  ...     -0.384455   \n",
      "4                1.238734             0.372623  ...     -0.384455   \n",
      "...                   ...                  ...  ...           ...   \n",
      "1086231          2.023775             0.372623  ...      1.315264   \n",
      "1086232          0.856823             0.372623  ...      3.014984   \n",
      "1086233         -0.628389            -0.694720  ...     -0.384455   \n",
      "1086234         -1.052735            -0.694720  ...     -0.384455   \n",
      "1086235          1.493342            -0.694720  ...     -0.384455   \n",
      "\n",
      "         num__pub_rec_bankruptcies  num__revol_bal  num__revol_util  \\\n",
      "0                        -0.359252       -0.591643        -1.505575   \n",
      "1                        -0.359252        0.842038         0.342899   \n",
      "2                        -0.359252        0.530750         0.072391   \n",
      "3                        -0.359252       -0.297470         0.580619   \n",
      "4                        -0.359252        0.417033         1.228200   \n",
      "...                            ...             ...              ...   \n",
      "1086231                   2.237124       -0.634607        -1.583449   \n",
      "1086232                   2.237124       -0.346741        -1.144897   \n",
      "1086233                  -0.359252       -0.343962        -1.521970   \n",
      "1086234                  -0.359252       -0.714270        -1.751492   \n",
      "1086235                  -0.359252       -0.101310         0.810141   \n",
      "\n",
      "         num__tax_liens  label__emp_title  label__home_ownership  \\\n",
      "0             -0.156755              33.0                    0.0   \n",
      "1             -0.156755              33.0                    1.0   \n",
      "2             -0.156755              41.0                    0.0   \n",
      "3             -0.156755              33.0                    0.0   \n",
      "4             -0.156755              33.0                    0.0   \n",
      "...                 ...               ...                    ...   \n",
      "1086231       -0.156755              33.0                    0.0   \n",
      "1086232        2.557235              33.0                    2.0   \n",
      "1086233       -0.156755              29.0                    0.0   \n",
      "1086234       -0.156755              33.0                    2.0   \n",
      "1086235       -0.156755               6.0                    0.0   \n",
      "\n",
      "         label__purpose  ord__grade  ord__sub_grade  \n",
      "0                   3.0         1.0             6.0  \n",
      "1                   2.0         1.0             6.0  \n",
      "2                   2.0         0.0             2.0  \n",
      "3                   2.0         1.0             7.0  \n",
      "4                   2.0         3.0            19.0  \n",
      "...                 ...         ...             ...  \n",
      "1086231             2.0         2.0            12.0  \n",
      "1086232             8.0         4.0            21.0  \n",
      "1086233             2.0         0.0             4.0  \n",
      "1086234             1.0         1.0             8.0  \n",
      "1086235             2.0         4.0            23.0  \n",
      "\n",
      "[957145 rows x 31 columns], 'y_train': 0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          1\n",
      "          ..\n",
      "1086231    0\n",
      "1086232    1\n",
      "1086233    0\n",
      "1086234    0\n",
      "1086235    1\n",
      "Name: target, Length: 957145, dtype: int32}\n"
     ]
    }
   ],
   "source": [
    "# Open the pickle file in read-binary mode\n",
    "with open(\"../models/needed_variables.pkl\", \"rb\") as f:\n",
    "    data = joblib.load(f)\n",
    "\n",
    "print(data)\n",
    "\n",
    "with open(\"../models/needed_variables2.pkl\", \"rb\") as f:\n",
    "    data2 = joblib.load(f)\n",
    "\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f760351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract variables\n",
    "y_test = data.get(\"y_test\")\n",
    "y_pred = data.get(\"y_pred_test\")\n",
    "y_proba = data.get(\"y_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dc490",
   "metadata": {},
   "source": [
    "# Performance metrics \n",
    "\n",
    "## Accronyms used :\n",
    "\n",
    "some accrocnyms in terms of a confusion matrix (for classification):\n",
    "TP (True Positive): correctly predicted positive cases\n",
    "\n",
    "TN (True Negative): correctly predicted negative cases\n",
    "\n",
    "FP (False Positive): negatives wrongly predicted as positives\n",
    "\n",
    "FN (False Negative): positives wrongly predicted as negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a767444",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "accuracy = nb of correct predictions / total number of predictions\n",
    "accuracy = (TP+TN) / (TP + TN + FP + FN)\n",
    "\n",
    "interpretation:\n",
    "Out of all predictions, 0.723 were correct (either the model correctly identified a positive case or correctly rejected a negative case).\n",
    "\n",
    "Only 0.277 were misclassified. This may be considered high if mistakes have a high cost.\n",
    "\n",
    "Although this score does not guarantee the overall well performance of the model. Accuracy alone can be misleading when the dataset is\n",
    "imbalanced (e.g., 95% negatives, 5% positives). In such cases, a model predicting only the majority class could have high\n",
    "accuracy (95%) but fail to detect the minority class. That’s why we also look at sensitivity, specificity, AUC, and Brier score for a fuller picture.\n",
    "\n",
    "In our case, the data is **. So let's look at other performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0315acb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227323235276917"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72e331",
   "metadata": {},
   "source": [
    "## Sensitivity\n",
    "\n",
    "Sensitivity measures the ability of a model to correctly identify actual positives.\n",
    "sensitivity = TP / (TP + FN)\n",
    "\n",
    "High sensitivity = few positives are missed.\n",
    "Low sensitivity = the model fails to catch many true positives.\n",
    "\n",
    "\n",
    "How does it complement accuracy? :\n",
    "Accuracy looks at overall correctness (both positives and negatives). Sensitivity zooms in on how well positives are captured.\n",
    "We can have high accuracy but low sensitivity in imbalanced cases.\n",
    "Example: If only 1% of patients have a rare disease, a model predicting “healthy” for everyone is 99% accurate but has 0% sensitivity.\n",
    "\n",
    "We use sensitivity when missing positives is costly.\n",
    "\n",
    "Of all the actual positive cases, our model correctly detected 52%. The model seems to do fairly well overall (72.3%), but its performance on the positive class is weak. This usually happens in imbalanced datasets. It might be acceptable if false positives are more costly than false negatives, such as in credit scoring cases.\n",
    "\n",
    "Sensitivity tells you how many actual positives caught, but it ignores how many false alarms (false positives) generated.\n",
    "Hence sensitivity alone can be misleading: a model that predicts everything as positive has 100% sensitivity but terrible precision.\n",
    "Accuracy + Sensitivity still leave gaps : Even if a model shows high accuracy and high sensitivity, it can still be misleading because neither metric tells you anything about false positives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e0aba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5189917731489585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Sensitivity (Recall : the true positive rate)\n",
    "sensitivity = recall_score(y_test, y_pred)\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf2d05",
   "metadata": {},
   "source": [
    "## Specificity\n",
    "\n",
    "High specificity = very few false alarms (few false positives).\n",
    "Low specificity = many false alarms (lots of false positives).\n",
    "\n",
    "sensitivity vs specificity:\n",
    "Sensitivity (Recall) = how well positives are caught (minimizing false negatives).\n",
    "Specificity = how well negatives are caught (minimizing false positives).\n",
    "\n",
    "Of all the risky applicants, the model correctly recognized as negative 76.4%. When the true condition is negative, the model correctly identifies about 3 out of 4. This is substantially better than its performance on positives.\n",
    "\n",
    "This tells us that the model is biased toward predicting negatives (high specificity compared to sensitivity). It performs much better at ruling out negatives than at detecting positives. In the case of credit scoring, this might be more acceptable if false positives are costlier than false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7383da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635948744953485"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Specificity (true negative rate)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e9b51",
   "metadata": {},
   "source": [
    "## AUC\n",
    "\n",
    "It is one of the most widely used model evaluation metrics.\n",
    "\n",
    "AUC stands for Area Under the Curve.\n",
    "The “curve” here usually means the ROC curve (Receiver Operating Characteristic curve).\n",
    "So, ROC-AUC measures the area under the ROC curve.\n",
    "\n",
    "The ROC curve plots two things at various decision thresholds:\n",
    "True Positive Rate (TPR) = Sensitivity in an axis (usually y axis)\n",
    "False Positive Rate (FPR) = 1 – Specificity in the other axis\n",
    "Each point on the curve corresponds to a threshold used to classify probabilities into positive/negative.\n",
    "A perfect model under ROC, which at some threshold has a TPR of 1.0 and a FPR of 0.0, can be represented by either a point at (0, 1)\n",
    "The curve shows the trade-off between sensitivity and specificity as you move the threshold.\n",
    "\n",
    "The area under the ROC curve (AUC) represents the probability that the model, if given a randomly chosen positive and negative example, will rank the positive higher than the negative. While the ROC curve gives a visual representation of the trade-off between sensitivity and specificity for different thresholds, AUC provides a numerical summary of the performance of the model across all threshold values. \n",
    "\n",
    "Interpreting AUC:\n",
    "AUC = 1.0 : perfect model (separates positives and negatives flawlessly).\n",
    "    The perfect model under ROC described above, containing a square with sides of length 1, has an area under the curve (AUC) of 1.0. This means there is a 100% probability that the model will correctly rank a randomly chosen positive example higher than a randomly chosen negative example.\n",
    "    It is the probability that a randomly chosen positive gets a higher score than a randomly chosen negative.\n",
    "AUC = 0.5 : worthless model (random guessing).\n",
    "AUC < 0.5 : actively misleading (worse than random; could be flipped).\n",
    "\n",
    "Our model has an AUC of 0.71. This indicates moderate ability to separate positives from negatives (better than random guessing = 0.5, but far from excellent). An AUC of 0.71 means that, on average, if we randomly take a positive and a negative example, the model assigns a higher score to the positive 71% of the time.\n",
    "\n",
    "Sensitivity = 52% is low, while specificity is much higher (76.4%). That imbalance suggests the threshold is set in a way that favors negatives. Since the AUC is moderate (0.71, not close to 0.5), the model has the ability to trade some specificity for more sensitivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efa39b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7098773799495443"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. AUC (Area under ROC curve)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236cf1d",
   "metadata": {},
   "source": [
    "## Brier score\n",
    "\n",
    "Brier score loss is another important metric, but unlike accuracy, sensitivity, or AUC, it evaluates probabilistic predictions rather than just yes/no classifications.\n",
    "It measures the accuracy of probabilistic predictions.\n",
    "The Brier score measures the mean squared difference between the predicted probability and the actual outcome (0 or 1). It penalizes both wrong predictions and overconfident predictions.\n",
    "Interpretation:\n",
    "0 = perfect probabilistic predictions.\n",
    "1 = worst possible (completely wrong with absolute certainty).\n",
    "\n",
    "A score of 0.182 is quite decent — it suggests that the model’s predicted probabilities are reasonably well calibrated, i.e., when it predicts a 70% chance of positive, positives actually happen about 70% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2f46e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18218767491983826"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Brier Score\n",
    "brier = brier_score_loss(y_test, y_proba)\n",
    "brier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471377b",
   "metadata": {},
   "source": [
    "## summarry / global interpretation\n",
    "\n",
    "The model is imbalanced in its performance — it’s moderately strong at identifying negatives but weak at catching positives. The overall accuracy (72.3%) hides this imbalance. This model is moderately good at ranking cases and produces fairly well-calibrated probabilities, we may consider modifying the threashold.\n",
    "\n",
    "In practice, the AUC suggest we could lower the threshold to classify more cases as positive. This would increase sensitivity (catch more positives). But this comes at the cost of lower specificity (more false alarms). If the cost of missing positives is high, we could consider shifting the threshold to increase sensitivity, even if specificity drops.\n",
    "If negatives are more important, the current setup may be acceptable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac9ad403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723\n",
      "Sensitivity: 0.519\n",
      "Specificity: 0.764\n",
      "AUC: 0.710\n",
      "Brier Score: 0.182\n"
     ]
    }
   ],
   "source": [
    "#summarry / global interpretation\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "print(f\"Brier Score: {brier:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ed68e",
   "metadata": {},
   "source": [
    "# Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85e54a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostClassifier object at 0x00000267297026C0>\n"
     ]
    }
   ],
   "source": [
    "# Open the pickle file in read-binary mode\n",
    "with open(\"../models/step2_catboost_timesplit.pkl\", \"rb\") as f:\n",
    "    model = joblib.load(f)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a47dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed variables\n",
    "X_train = data2.get(\"X_train\")\n",
    "y_train = data2.get(\"y_train\")\n",
    "X_test = data.get(\"X_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2beced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 3   # number of resampled datasets to train on\n",
    "predictions_list = []\n",
    "scores = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # 1. Bootstrap sample from training data\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, replace=True, random_state=i)\n",
    "\n",
    "    # 2. Train CatBoost\n",
    "    model_boot = model\n",
    "    model_boot.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # 3. Predict on the fixed test set\n",
    "    preds = model_boot.predict_proba(X_test)[:, 1]  # probability of positive class\n",
    "    predictions_list.append(preds) # list of 1D arrays of predictions\n",
    "\n",
    "    # 4. Evaluate performance\n",
    "    score = accuracy_score(y_test, (preds > 0.5).astype(int))\n",
    "    scores.append(score)\n",
    "\n",
    "\n",
    "predictions_array = np.array(predictions_list) # predictions_array has shape (n_bootstrap, n_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51fa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pairwise Euclidean distance between models: 10.5912\n",
      "Average accuracy: 0.735\n"
     ]
    }
   ],
   "source": [
    "# compute distances between predictions\n",
    "\n",
    "# pdist computes all pairwise distances between the rows of the array, so between each bootstrap\n",
    "dist_matrix = squareform(pdist(predictions_array, metric=\"euclidean\"))\n",
    "# dist_matrix is a full symmetric matrix of shape (n_bootstrap, n_bootstrap)\n",
    "\n",
    "# average distance across all pairs\n",
    "avg_dist = np.mean(dist_matrix[np.triu_indices_from(dist_matrix, k=1)])\n",
    "\n",
    "print(f\"Average pairwise Euclidean distance between models: {avg_dist:.4f}\")\n",
    "\n",
    "\n",
    "# Performance Stability: variance of accuracy\n",
    "mean_acc = np.mean(scores)\n",
    "\n",
    "print(f\"Average accuracy: {mean_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bd673ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003097027243613833"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dist_per_point = avg_dist / len(X_test)\n",
    "avg_dist_per_point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d576c",
   "metadata": {},
   "source": [
    "That means on average, across bootstrap models, predictions differ by less than 1% in probability per test point. This is stable with respect to resampling the training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
